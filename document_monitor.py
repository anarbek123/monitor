# –ó–∞–º–µ–Ω–∏—Ç—å –∏–º–ø–æ—Ä—Ç
try:
    from enhanced_browser_bot import SuperHumanBrowserBot as AdvancedBrowserBot
except ImportError:
    from browser_bot import AdvancedBrowserBot
import os
import requests
import time
import json
import hashlib
import re
import random
from urllib.parse import urljoin, urlparse, unquote
from bs4 import BeautifulSoup
from pathlib import Path
import logging
from datetime import datetime, timedelta
import schedule

class HumanLikeDocumentMonitor:
    def __init__(self, config_file='monitor_config.json'):
        self.config_file = config_file
        self.config = self.load_config()
        self.setup_logging()
        self.downloaded_files = self.load_downloaded_history()
        self.discovered_files = self.load_discovered_files()
        self.session = requests.Session()
        self.setup_human_like_session()
        self.initial_scan_completed = self.check_initial_scan_status()
        self.is_first_run = self.check_if_first_run()
        self.browser_bot = None
        
    def get_browser_bot(self):
        """–ü–æ–ª—É—á–∏—Ç—å —ç–∫–∑–µ–º–ø–ª—è—Ä –±—Ä–∞—É–∑–µ—Ä–Ω–æ–≥–æ –±–æ—Ç–∞ (–ª–µ–Ω–∏–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è)"""
        if self.browser_bot is None:
            try:
                from browser_bot import AdvancedBrowserBot
                # –ó–∞–ø—É—Å–∫–∞–µ–º –≤ headless —Ä–µ–∂–∏–º–µ –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–Ω–∞, —Å GUI –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
                headless_mode = self.config.get('browser_headless', True)
                self.browser_bot = AdvancedBrowserBot(
                    headless=headless_mode, 
                    stealth_mode=True
                )
                self.logger.info("ü§ñ –ë—Ä–∞—É–∑–µ—Ä–Ω—ã–π –±–æ—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            except ImportError:
                self.logger.warning("‚ö†Ô∏è –ë—Ä–∞—É–∑–µ—Ä–Ω—ã–π –±–æ—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install selenium undetected-chromedriver")
                self.browser_bot = None
            except Exception as e:
                self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –±—Ä–∞—É–∑–µ—Ä–Ω–æ–≥–æ –±–æ—Ç–∞: {e}")
                self.browser_bot = None
        
        return self.browser_bot
    
    def check_if_first_run(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–≤–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ –ø—Ä–æ–≥—Ä–∞–º–º—ã"""
        first_run_file = 'first_run_completed.json'
        try:
            with open(first_run_file, 'r') as f:
                data = json.load(f)
                is_first = not data.get('completed', False)
                if is_first:
                    self.logger.info("üÜï –≠—Ç–æ –ø–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫ –ø—Ä–æ–≥—Ä–∞–º–º—ã")
                else:
                    self.logger.debug("–ü—Ä–æ–≥—Ä–∞–º–º–∞ —É–∂–µ –∑–∞–ø—É—Å–∫–∞–ª–∞—Å—å —Ä–∞–Ω–µ–µ")
                return is_first
        except FileNotFoundError:
            self.logger.info("üÜï –§–∞–π–ª –ø–µ—Ä–≤–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω - —ç—Ç–æ –ø–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫")
            return True
    
    def mark_first_run_completed(self):
        """–û—Ç–º–µ—Ç–∏—Ç—å –ø–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫ –∫–∞–∫ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–π"""
        first_run_file = 'first_run_completed.json'
        with open(first_run_file, 'w') as f:
            json.dump({
                'completed': True,
                'completed_at': datetime.now().isoformat()
            }, f, indent=2)
        self.is_first_run = False
    
    def is_working_hours(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—á–∏—Ö —á–∞—Å–æ–≤ (9:00-18:00, –ø–Ω-–ø—Ç)"""
        now = datetime.now()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–µ–Ω—å –Ω–µ–¥–µ–ª–∏ (0=–ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫, 6=–≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ)
        if now.weekday() >= 5:  # —Å—É–±–±–æ—Ç–∞ –∏–ª–∏ –≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ
            self.logger.debug(f"–í—ã—Ö–æ–¥–Ω–æ–π –¥–µ–Ω—å: {now.strftime('%A')}")
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ä–µ–º—è (9:00-18:00)
        hour = now.hour
        is_work_time = 9 <= hour < 18
        
        if not is_work_time:
            self.logger.debug(f"–ù–µ—Ä–∞–±–æ—á–µ–µ –≤—Ä–µ–º—è: {hour}:00 (—Ä–∞–±–æ—Ç–∞–µ–º 9:00-18:00)")
        
        return is_work_time
    
    def load_config(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–∑ —Ñ–∞–π–ª–∞"""
        default_config = {
            "urls": [
                "https://court.aifc.kz/en/judgments",
                "https://court.aifc.kz/en/legislation"
            ],
            "download_dir": "aifc_documents",
            "check_interval_minutes": 120,
            "file_extensions": [".pdf", ".doc", ".docx", ".xls", ".xlsx", ".txt", ".zip", ".rar"],
            "max_depth": 3,
            "timeout": 30,
            "browser_enabled": True,
            "browser_headless": True,
            "browser_fallback": True,
            "max_filename_length": 150,
            "human_behavior": {
                "browsing_probability": 0.7,
                "min_session_time": 120,
                "max_session_time": 600,
                "pages_per_session": [3, 8],
                "interval_variation": 0.3,
                "short_break_probability": 0.05,
                "long_break_probability": 0.05,
                "mini_visit_probability": 0.001,
                "initial_scan_days": 15,
                "monitoring_cycle_days_min": 7,
                "monitoring_cycle_days_max": 10,
                "working_hours_start": 9,
                "working_hours_end": 18,
                "working_days": [0, 1, 2, 3, 4],
                "first_run_always_download": True,
                "initial_download_probability_min": 0.5,
                "initial_download_probability_max": 0.8,
                "monitoring_download_probability_min": 0.15,
                "monitoring_download_probability_max": 0.45
            }
        }
        
        try:
            with open(self.config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
                for key, value in default_config.items():
                    if key not in config:
                        config[key] = value
                return config
        except FileNotFoundError:
            with open(self.config_file, 'w', encoding='utf-8') as f:
                json.dump(default_config, f, indent=4, ensure_ascii=False)
            print(f"–°–æ–∑–¥–∞–Ω —Ñ–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {self.config_file}")
            return default_config
    
    def setup_logging(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('document_monitor.log', encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
        
    def load_downloaded_history(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏ —Å–∫–∞—á–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
        try:
            with open('downloaded_files.json', 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            return {}
    
    def save_downloaded_history(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ —Å–∫–∞—á–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
        with open('downloaded_files.json', 'w', encoding='utf-8') as f:
            json.dump(self.downloaded_files, f, indent=2, ensure_ascii=False)
    
    def load_discovered_files(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å–ø–∏—Å–∫–∞ –≤—Å–µ—Ö –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
        try:
            with open('discovered_files.json', 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            return {
                'files': {},
                'last_full_scan': None,
                'initial_scan_completed': False,
                'scan_start_date': datetime.now().isoformat()
            }
    
    def save_discovered_files(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
        with open('discovered_files.json', 'w', encoding='utf-8') as f:
            json.dump(self.discovered_files, f, indent=2, ensure_ascii=False)
    
    def check_initial_scan_status(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ –ø–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–æ–≥–æ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è"""
        # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è - –≤—Å–µ–≥–¥–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º False –¥–ª—è –¥–µ–º–æ
        return False
    
    def setup_human_like_session(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å–µ—Å—Å–∏–∏ –¥–ª—è –∏–º–∏—Ç–∞—Ü–∏–∏ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        # –†–æ—Ç–∞—Ü–∏—è User-Agent'–æ–≤
        self.user_agents = [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/119.0',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.1 Safari/605.1.15',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Edge/119.0.0.0 Safari/537.36'
        ]
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –∫–∞–∫ —É —Ä–µ–∞–ª—å–Ω–æ–≥–æ –±—Ä–∞—É–∑–µ—Ä–∞
        self.session.headers.update({
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.9,ru;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'DNT': '1',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'same-origin',
            'Cache-Control': 'max-age=0'
        })
    
    def get_random_user_agent(self):
        """–ü–æ–ª—É—á–∏—Ç—å —Å–ª—É—á–∞–π–Ω—ã–π User-Agent"""
        return random.choice(self.user_agents)
    
    def human_delay(self, min_seconds=2, max_seconds=8):
        """–ß–µ–ª–æ–≤–µ—á–µ—Å–∫–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –¥–µ–π—Å—Ç–≤–∏—è–º–∏"""
        delay = random.uniform(min_seconds, max_seconds)
        self.logger.debug(f"–ü–∞—É–∑–∞ {delay:.1f} —Å–µ–∫—É–Ω–¥...")
        time.sleep(delay)
    
    def should_download_now(self):
        """–†–µ—à–∞–µ—Ç, —Å—Ç–æ–∏—Ç –ª–∏ —Å–∫–∞—á–∏–≤–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å–µ–π—á–∞—Å (–∞–¥–∞–ø—Ç–∏–≤–Ω–æ)"""
        
        # –ü–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫ - –≤—Å–µ–≥–¥–∞ —Å–∫–∞—á–∏–≤–∞–µ–º –í–°–ï –¥–æ–∫—É–º–µ–Ω—Ç—ã
        if self.is_first_run:
            self.logger.info("üöÄ –ü–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫ - —Å–∫–∞—á–∏–≤–∞–µ–º –í–°–ï –¥–æ–∫—É–º–µ–Ω—Ç—ã!")
            return True
        
        # –û–±—ã—á–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ - –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–±–æ—á–∏–µ —á–∞—Å—ã
        if not self.is_working_hours():
            self.logger.info("üí§ –ù–µ—Ä–∞–±–æ—á–µ–µ –≤—Ä–µ–º—è - —Ç–æ–ª—å–∫–æ –±—Ä–∞—É–∑–∏–Ω–≥")
            return False
        
        # –í —Ä–∞–±–æ—á–∏–µ —á–∞—Å—ã –≤—Å–µ–≥–¥–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –Ω–æ–≤—ã–µ/–∏–∑–º–µ–Ω–µ–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
        self.logger.info("üîç –†–µ–∂–∏–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ - –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–æ–≤—ã–µ –∏ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã")
        return True
    
    def crawl_with_browser_bot(self, url):
        """–û–±—Ö–æ–¥ —Å–∞–π—Ç–∞ —Å –ø–æ–º–æ—â—å—é –±—Ä–∞—É–∑–µ—Ä–Ω–æ–≥–æ –±–æ—Ç–∞"""
        bot = self.get_browser_bot()
        if not bot:
            self.logger.warning("üîÑ –ë—Ä–∞—É–∑–µ—Ä–Ω—ã–π –±–æ—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—ã–π –º–µ—Ç–æ–¥")
            return []
        
        try:
            self.logger.info(f"ü§ñ –ò—Å–ø–æ–ª—å–∑—É–µ–º –±—Ä–∞—É–∑–µ—Ä–Ω—ã–π –±–æ—Ç –¥–ª—è: {url}")
            
            # –ò–º–∏—Ç–∏—Ä—É–µ–º —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ
            bot.simulate_human_browsing("https://court.aifc.kz")
            
            # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ —Ü–µ–ª–µ–≤—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
            if bot.visit_page_like_human(url):
                
                # –ò—â–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
                documents = bot.find_document_links()
                
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –Ω—É–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
                document_urls = []
                for doc in documents:
                    document_urls.append(doc['url'])
                    self.logger.info(f"üîó –ù–∞–π–¥–µ–Ω –±—Ä–∞—É–∑–µ—Ä–æ–º: {doc['url']}")
                
                return document_urls
            else:
                self.logger.warning(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É –≤ –±—Ä–∞—É–∑–µ—Ä–µ: {url}")
                return []
                
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞–±–æ—Ç—ã –±—Ä–∞—É–∑–µ—Ä–Ω–æ–≥–æ –±–æ—Ç–∞: {e}")
            return []
    
    def create_aifc_directory_structure(self, url, base_dir):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø–∞–ø–æ–∫ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ –¥–ª—è AIFC Court —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–µ–π"""
        parsed_url = urlparse(url)
        url_lower = url.lower()
        
        # –ü–æ–¥—Ä–æ–±–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        folder_name = 'Other_Documents'  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
        
        # –°—É–¥–µ–±–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è –∏ –¥–µ–ª–∞
        if any(keyword in url_lower for keyword in [
            'judgments', '/uploads/', 'case%20no', 'judgment', 
            'case_no', 'case-no', 'decision', 'ruling'
        ]):
            folder_name = 'Judgments'
            self.logger.debug(f"üìÇ –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ –∫–∞–∫ —Å—É–¥–µ–±–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ: {url}")
        
        # –ó–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–æ –∏ –ø—Ä–∞–≤–∏–ª–∞
        elif any(keyword in url_lower for keyword in [
            'legislation', '/legals/', 'regulations', 'rules', 
            'policy', 'consultation-paper', 'guidance', 'notice',
            'amendment', 'circular', 'directive', 'order'
        ]):
            folder_name = 'Legislation'
            self.logger.debug(f"üìÇ –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ –∫–∞–∫ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–æ: {url}")
        
        # –ï—Å–ª–∏ —Å–æ–¥–µ—Ä–∂–∏—Ç —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ AIFC
        elif any(keyword in url_lower for keyword in [
            'aifc-court-regulations', 'aifc-court-rules', 
            'template-of-offering', 'afsa-policy'
        ]):
            folder_name = 'Legislation'
            self.logger.debug(f"üìÇ –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ –∫–∞–∫ AIFC –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–æ: {url}")
        
        else:
            self.logger.debug(f"üìÇ –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ –∫–∞–∫ –ø—Ä–æ—á–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã: {url}")
        
        # –°–æ–∑–¥–∞–µ–º –æ—Å–Ω–æ–≤–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        full_path = os.path.join(base_dir, 'AIFC_Court', folder_name)
        
        # –î–ª—è —Ä–µ—à–µ–Ω–∏–π —Å—É–¥–æ–≤ —Å–æ–∑–¥–∞–µ–º –ø–æ–¥–ø–∞–ø–∫–∏ –ø–æ –≥–æ–¥–∞–º
        if folder_name == 'Judgments':
            year_match = re.search(r'20\d{2}', url)
            if year_match:
                year = year_match.group()
                full_path = os.path.join(full_path, year)
                self.logger.debug(f"üìÖ –°–æ–∑–¥–∞–Ω–∞ –ø–æ–¥–ø–∞–ø–∫–∞ –¥–ª—è –≥–æ–¥–∞: {year}")
        
        # –î–ª—è –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –º–æ–∂–Ω–æ —Å–æ–∑–¥–∞—Ç—å –ø–æ–¥–ø–∞–ø–∫–∏ –ø–æ —Ç–∏–ø—É
        elif folder_name == 'Legislation':
            if 'consultation-paper' in url_lower:
                full_path = os.path.join(full_path, 'Consultation_Papers')
            elif 'guidance' in url_lower:
                full_path = os.path.join(full_path, 'Guidance_Documents')
            elif 'notice' in url_lower:
                full_path = os.path.join(full_path, 'Notices')
            elif 'template' in url_lower:
                full_path = os.path.join(full_path, 'Templates')
        
        # –í–∫–ª—é—á–∞–µ–º –ø–æ–¥–¥–µ—Ä–∂–∫—É –¥–ª–∏–Ω–Ω—ã—Ö –ø—É—Ç–µ–π –≤ Windows
        if os.name == 'nt':  # Windows
            if not full_path.startswith('\\\\?\\'):
                full_path = '\\\\?\\' + os.path.abspath(full_path)
        
        try:
            os.makedirs(full_path, exist_ok=True)
        except OSError as e:
            if "path too long" in str(e).lower() or e.errno == 2:
                # Fallback: —Å–æ–∑–¥–∞–µ–º –±–æ–ª–µ–µ –∫–æ—Ä–æ—Ç–∫–∏–π –ø—É—Ç—å
                self.logger.warning(f"‚ö†Ô∏è –ü—É—Ç—å —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π, —Å–æ–∑–¥–∞–µ–º —Å–æ–∫—Ä–∞—â–µ–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é")
                short_path = os.path.join(base_dir, 'AIFC_Court', folder_name[:20])
                os.makedirs(short_path, exist_ok=True)
                return short_path
            else:
                raise
        
        return full_path
    
    def get_clean_filename(self, url, content_disposition=None):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —á–∏—Å—Ç–æ–≥–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –¥–ª–∏–Ω–Ω—ã—Ö –∏–º–µ–Ω"""
        max_length = self.config.get('max_filename_length', 150)
        
        if content_disposition:
            filename_match = re.search(r'filename[*]?=["\']?([^"\';\r\n]+)', content_disposition)
            if filename_match:
                filename = filename_match.group(1).strip()
                if filename:
                    filename = unquote(filename)
        else:
            parsed_url = urlparse(url)
            filename = os.path.basename(unquote(parsed_url.path))
        
        if 'court.aifc.kz' in url:
            if filename:
                filename = filename.replace('%20', ' ')
                filename = re.sub(r'[<>:"/\\|?*]', '_', filename)
                
                if '.' not in filename and '/uploads/' in url:
                    filename += '.pdf'
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã—Ö –∏–º–µ–Ω —Ñ–∞–π–ª–æ–≤
        if len(filename) > max_length:
            name, ext = os.path.splitext(filename)
            
            # –°–æ–∑–¥–∞–µ–º —Å–æ–∫—Ä–∞—â–µ–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é
            if len(name) > max_length - len(ext) - 10:  # –û—Å—Ç–∞–≤–ª—è–µ–º –º–µ—Å—Ç–æ –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –∏ —Ö–µ—à–∞
                # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ —Å–ª–æ–≤–∞ + —Ö–µ—à URL –¥–ª—è —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏
                words = name.split('-')
                short_name = '-'.join(words[:3])  # –ü–µ—Ä–≤—ã–µ 3 —Å–ª–æ–≤–∞
                url_hash = hashlib.md5(url.encode()).hexdigest()[:8]
                
                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
                available_length = max_length - len(ext) - len(url_hash) - 1
                if len(short_name) > available_length:
                    short_name = short_name[:available_length]
                
                filename = f"{short_name}_{url_hash}{ext}"
                
                self.logger.info(f"üìù –°–æ–∫—Ä–∞—â–µ–Ω–æ –¥–ª–∏–Ω–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞:")
                self.logger.info(f"   –ò—Å—Ö–æ–¥–Ω–æ–µ: {name[:50]}...")
                self.logger.info(f"   –ù–æ–≤–æ–µ: {filename}")
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
        if not filename or '.' not in filename:
            url_hash = hashlib.md5(url.encode()).hexdigest()[:8]
            if 'judgments' in url.lower():
                filename = f"judgment_{url_hash}.pdf"
            elif 'legislation' in url.lower() or 'legals' in url.lower():
                filename = f"legislation_{url_hash}.pdf"
            else:
                filename = f"document_{url_hash}.pdf"
        
        return filename
    
    def update_discovered_files(self, documents):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
        current_time = datetime.now().isoformat()
        
        for doc_url in documents:
            if doc_url not in self.discovered_files['files']:
                self.discovered_files['files'][doc_url] = {
                    'first_seen': current_time,
                    'last_seen': current_time,
                    'downloaded': False,
                    'is_new': True  # –ü–æ–º–µ—á–∞–µ–º –∫–∞–∫ –Ω–æ–≤—ã–π
                }
                self.logger.info(f"üÜï –û–±–Ω–∞—Ä—É–∂–µ–Ω –Ω–æ–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç: {doc_url}")
            else:
                self.discovered_files['files'][doc_url]['last_seen'] = current_time
                # –ï—Å–ª–∏ —Ñ–∞–π–ª —É–∂–µ –±—ã–ª, –Ω–æ –Ω–µ —Å–∫–∞—á–∞–Ω - —Ç–æ–∂–µ —Å—á–∏—Ç–∞–µ–º –Ω–æ–≤—ã–º
                if not self.discovered_files['files'][doc_url].get('downloaded', False):
                    self.discovered_files['files'][doc_url]['is_new'] = True
        
        self.discovered_files['last_full_scan'] = current_time
        self.save_discovered_files()
    
    def get_files_to_download(self, documents):
        """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–∞–∫–∏–µ —Ñ–∞–π–ª—ã –Ω—É–∂–Ω–æ —Å–∫–∞—á–∞—Ç—å"""
        if self.is_first_run:
            # –ü–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫ - —Å–∫–∞—á–∏–≤–∞–µ–º –í–°–ï –¥–æ–∫—É–º–µ–Ω—Ç—ã
            self.logger.info(f"üìã –ü–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫: –ø–ª–∞–Ω–∏—Ä—É–µ–º —Å–∫–∞—á–∞—Ç—å –í–°–ï {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
            return documents
        
        # –†–µ–∂–∏–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ - —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ –∏ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã–µ
        files_to_download = []
        
        for doc_url in documents:
            file_info = self.discovered_files['files'].get(doc_url, {})
            
            # –ù–æ–≤—ã–π —Ñ–∞–π–ª
            if file_info.get('is_new', False):
                files_to_download.append(doc_url)
                self.logger.info(f"üÜï –ö —Å–∫–∞—á–∏–≤–∞–Ω–∏—é: –Ω–æ–≤—ã–π —Ñ–∞–π–ª {doc_url}")
            
            # –§–∞–π–ª –Ω–µ –±—ã–ª —Å–∫–∞—á–∞–Ω —Ä–∞–Ω–µ–µ
            elif not file_info.get('downloaded', False):
                files_to_download.append(doc_url)
                self.logger.info(f"üì• –ö —Å–∫–∞—á–∏–≤–∞–Ω–∏—é: –Ω–µ —Å–∫–∞—á–∞–Ω–Ω—ã–π —Ñ–∞–π–ª {doc_url}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –∏–∑–º–µ–Ω–µ–Ω–∏—è —É–∂–µ —Å–∫–∞—á–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
            elif doc_url in self.downloaded_files:
                files_to_download.append(doc_url)
                self.logger.debug(f"üîÑ –ö –ø—Ä–æ–≤–µ—Ä–∫–µ –Ω–∞ –∏–∑–º–µ–Ω–µ–Ω–∏—è: {doc_url}")
        
        self.logger.info(f"üìä –ö –æ–±—Ä–∞–±–æ—Ç–∫–µ: {len(files_to_download)} –∏–∑ {len(documents)} —Ñ–∞–π–ª–æ–≤")
        return files_to_download
    
    def get_file_hash(self, content):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ö–µ—à–∞ —Ñ–∞–π–ª–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–π"""
        return hashlib.md5(content).hexdigest()
    
    def download_with_browser_bot(self, url, save_path):
        """–°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ —á–µ—Ä–µ–∑ –±—Ä–∞—É–∑–µ—Ä–Ω—ã–π –±–æ—Ç —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –∏–∑–º–µ–Ω–µ–Ω–∏–π"""
        bot = self.get_browser_bot()
        if not bot:
            return self.download_file_simple(url, save_path)
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω—É–∂–Ω–æ –ª–∏ –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞—Ç—å —Ñ–∞–π–ª
            file_exists = os.path.exists(save_path)
            old_hash = None
            
            if file_exists and url in self.downloaded_files:
                old_hash = self.downloaded_files[url]['hash']
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±—Ä–∞—É–∑–µ—Ä –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ñ–∞–π–ª–∞
            if bot.visit_page_like_human(url):
                
                # –ü–æ–ª—É—á–∞–µ–º –∫—É–∫–∏ –∏–∑ –±—Ä–∞—É–∑–µ—Ä–∞
                cookies = bot.driver.get_cookies()
                session_cookies = {}
                for cookie in cookies:
                    session_cookies[cookie['name']] = cookie['value']
                
                # –°–∫–∞—á–∏–≤–∞–µ–º —á–µ—Ä–µ–∑ requests —Å –∫—É–∫–∞–º–∏ –±—Ä–∞—É–∑–µ—Ä–∞
                headers = {
                    'User-Agent': bot.driver.execute_script("return navigator.userAgent;"),
                    'Referer': bot.driver.current_url
                }
                
                response = self.session.get(url, headers=headers, cookies=session_cookies, stream=True)
                response.raise_for_status()
                
                file_content = response.content
                file_hash = self.get_file_hash(file_content)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è
                if old_hash and old_hash == file_hash:
                    self.logger.debug(f"‚ö™ –§–∞–π–ª –Ω–µ –∏–∑–º–µ–Ω–∏–ª—Å—è: {os.path.basename(save_path)}")
                    return "unchanged"
                
                # –°–æ–∑–¥–∞–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é –µ—Å–ª–∏ —Ñ–∞–π–ª –∏–∑–º–µ–Ω–∏–ª—Å—è
                if file_exists and old_hash and old_hash != file_hash:
                    backup_path = save_path + f".backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                    import shutil
                    shutil.copy2(save_path, backup_path)
                    self.logger.info(f"üîÑ –§–∞–π–ª –∏–∑–º–µ–Ω–∏–ª—Å—è! –°–æ–∑–¥–∞–Ω–∞ —Ä–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è: {os.path.basename(backup_path)}")
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ–≤—ã–π —Ñ–∞–π–ª
                os.makedirs(os.path.dirname(save_path), exist_ok=True)
                with open(save_path, 'wb') as f:
                    f.write(file_content)
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                self.downloaded_files[url] = {
                    'hash': file_hash,
                    'path': save_path,
                    'downloaded_at': datetime.now().isoformat(),
                    'size': len(file_content),
                    'method': 'browser_bot'
                }
                
                # –ü–æ–º–µ—á–∞–µ–º —Ñ–∞–π–ª –∫–∞–∫ —Å–∫–∞—á–∞–Ω–Ω—ã–π
                if url in self.discovered_files['files']:
                    self.discovered_files['files'][url]['downloaded'] = True
                    self.discovered_files['files'][url]['last_downloaded'] = datetime.now().isoformat()
                    self.discovered_files['files'][url]['is_new'] = False
                
                if file_exists and old_hash != file_hash:
                    self.logger.info(f"üîÑüìÑ –û–±–Ω–æ–≤–ª–µ–Ω —Ñ–∞–π–ª: {os.path.basename(save_path)} ({len(file_content)} –±–∞–π—Ç)")
                    return "updated"
                else:
                    self.logger.info(f"üÜïüìÑ –°–∫–∞—á–∞–Ω –Ω–æ–≤—ã–π —Ñ–∞–π–ª: {os.path.basename(save_path)} ({len(file_content)} –±–∞–π—Ç)")
                    return "new"
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è —á–µ—Ä–µ–∑ –±—Ä–∞—É–∑–µ—Ä {url}: {e}")
            # Fallback –Ω–∞ –æ–±—ã—á–Ω—ã–π –º–µ—Ç–æ–¥
            return self.download_file_simple(url, save_path)
        
        return "failed"
    
    def download_file_simple(self, url, save_path):
        """–ü—Ä–æ—Å—Ç–æ–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ —á–µ—Ä–µ–∑ requests"""
        try:
            headers = {
                'User-Agent': self.get_random_user_agent(),
                'Accept': 'application/pdf,application/vnd.ms-excel,*/*',
            }
            
            response = self.session.get(url, headers=headers, timeout=self.config['timeout'], stream=True)
            response.raise_for_status()
            
            file_content = response.content
            file_hash = self.get_file_hash(file_content)
            
            if url in self.downloaded_files and self.downloaded_files[url]['hash'] == file_hash:
                self.logger.debug(f"–§–∞–π–ª –Ω–µ –∏–∑–º–µ–Ω–∏–ª—Å—è: {url}")
                return "unchanged"
            
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            
            with open(save_path, 'wb') as f:
                f.write(file_content)
            
            self.downloaded_files[url] = {
                'hash': file_hash,
                'path': save_path,
                'downloaded_at': datetime.now().isoformat(),
                'size': len(file_content),
                'method': 'requests'
            }
            
            self.logger.info(f"üìÑ –°–∫–∞—á–∞–Ω —Ñ–∞–π–ª: {save_path} ({len(file_content)} –±–∞–π—Ç)")
            return "new"
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ {url}: {str(e)}")
            return "failed"
    
    def human_like_session(self):
        """–ü—Ä–æ–≤–µ–¥–µ–Ω–∏–µ —á–µ–ª–æ–≤–µ–∫–æ–ø–æ–¥–æ–±–Ω–æ–π —Å–µ—Å—Å–∏–∏ –Ω–∞ —Å–∞–π—Ç–µ"""
        base_url = "https://court.aifc.kz"
        
        self.logger.info("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—É—é —Å–µ—Å—Å–∏—é –Ω–∞ —Å–∞–π—Ç–µ...")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≤—Ä–µ–º—è –∏ —Å—Ç–∞—Ç—É—Å —Ä–∞–±–æ—á–∏—Ö —á–∞—Å–æ–≤
        now = datetime.now()
        time_str = now.strftime("%H:%M")
        day_str = ["–ü–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫", "–í—Ç–æ—Ä–Ω–∏–∫", "–°—Ä–µ–¥–∞", "–ß–µ—Ç–≤–µ—Ä–≥", "–ü—è—Ç–Ω–∏—Ü–∞", "–°—É–±–±–æ—Ç–∞", "–í–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ"][now.weekday()]
        
        if self.is_first_run:
            self.logger.info(f"üïê {day_str} {time_str} - –ü–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫ –ø—Ä–æ–≥—Ä–∞–º–º—ã")
        elif self.is_working_hours():
            self.logger.info(f"üïê {day_str} {time_str} - –†–∞–±–æ—á–∏–µ —á–∞—Å—ã")
        else:
            self.logger.info(f"üïê {day_str} {time_str} - –ù–µ—Ä–∞–±–æ—á–µ–µ –≤—Ä–µ–º—è")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, —á—Ç–æ –±—É–¥–µ–º –¥–µ–ª–∞—Ç—å –≤ —ç—Ç–æ–π —Å–µ—Å—Å–∏–∏
        will_download = self.should_download_now()
        
        if will_download:
            self.logger.info("üìã –ü–ª–∞–Ω–∏—Ä—É–µ–º —Å–∫–∞—á–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ —ç—Ç–æ–π —Å–µ—Å—Å–∏–∏")
        else:
            self.logger.info("üëÄ –ü—Ä–æ—Å—Ç–æ –∏–∑—É—á–∞–µ–º —Å–∞–π—Ç –≤ —ç—Ç–æ–π —Å–µ—Å—Å–∏–∏")
        
        if will_download:
            # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–∫–∞—á–∏–≤–∞–Ω–∏—é –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            if self.is_first_run:
                self.logger.info("üì• –ü–ï–†–í–´–ô –ó–ê–ü–£–°–ö: –°–∫–∞—á–∏–≤–∞–µ–º –í–°–ï –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å —Å–∞–π—Ç–∞...")
            else:
                self.logger.info("üì• –ú–û–ù–ò–¢–û–†–ò–ù–ì: –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–æ–≤—ã–µ –∏ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã...")
            
            total_new = 0
            total_updated = 0
            total_unchanged = 0
            total_failed = 0
            
            for url in self.config['urls']:
                self.human_delay(3, 8)
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±—Ä–∞—É–∑–µ—Ä–Ω—ã–π –±–æ—Ç –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
                documents = self.crawl_with_browser_bot(url)
                
                self.logger.info(f"üìä –ù–∞–π–¥–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –Ω–∞ {url}: {len(documents)}")
                
                if documents:
                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å–ø–∏—Å–æ–∫ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
                    self.update_discovered_files(documents)
                    
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞–∫–∏–µ —Ñ–∞–π–ª—ã –Ω—É–∂–Ω–æ —Å–∫–∞—á–∞—Ç—å
                    files_to_download = self.get_files_to_download(documents)
                    
                    if files_to_download:
                        self.logger.info(f"üéØ –ö –æ–±—Ä–∞–±–æ—Ç–∫–µ: {len(files_to_download)} —Ñ–∞–π–ª–æ–≤")
                        
                        for i, doc_url in enumerate(files_to_download):
                            try:
                                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
                                self.logger.info(f"üì• [{i+1}/{len(files_to_download)}] –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º: {os.path.basename(doc_url)}")
                                
                                self.human_delay(1, 3)  # –£–º–µ–Ω—å—à–µ–Ω–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è –º–∞—Å—Å–æ–≤–æ–≥–æ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
                                
                                save_dir = self.create_aifc_directory_structure(doc_url, self.config['download_dir'])
                                filename = self.get_clean_filename(doc_url)
                                save_path = os.path.join(save_dir, filename)
                                
                                result = self.download_with_browser_bot(doc_url, save_path)
                                
                                if result == "new":
                                    total_new += 1
                                elif result == "updated":
                                    total_updated += 1
                                elif result == "unchanged":
                                    total_unchanged += 1
                                else:
                                    total_failed += 1
                                
                                # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
                                if (i + 1) % 5 == 0:
                                    self.save_downloaded_history()
                                    self.save_discovered_files()
                                    self.logger.info(f"üíæ –ü—Ä–æ–≥—Ä–µ—Å—Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω ({i+1}/{len(files_to_download)})")
                                    
                            except Exception as e:
                                self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {doc_url}: {str(e)}")
                                total_failed += 1
                    else:
                        self.logger.info("üìÇ –ù–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
                else:
                    self.logger.warning(f"‚ö†Ô∏è –î–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –Ω–∞ {url}")
        
            # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            self.print_download_statistics(total_new, total_updated, total_unchanged, total_failed)
            
            # –û—Ç–º–µ—á–∞–µ–º –ø–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫ –∫–∞–∫ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–π
            if self.is_first_run:
                self.mark_first_run_completed()
                self.logger.info("üéâ –ü–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫ –∑–∞–≤–µ—Ä—à–µ–Ω! –í—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å–∫–∞—á–∞–Ω—ã.")
                self.logger.info("üîÑ –°–ª–µ–¥—É—é—â–∏–µ –∑–∞–ø—É—Å–∫–∏ –±—É–¥—É—Ç —Ç–æ–ª—å–∫–æ –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è.")
        
        self.logger.info("üèÅ –ó–∞–≤–µ—Ä—à–∞–µ–º —Å–µ—Å—Å–∏—é")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        self.save_downloaded_history()
        self.save_discovered_files()
        
        # –ó–∞–∫—Ä—ã–≤–∞–µ–º –±—Ä–∞—É–∑–µ—Ä–Ω—ã–π –±–æ—Ç
        if self.browser_bot:
            try:
                self.browser_bot.close()
                self.browser_bot = None
                self.logger.info("üîí –ë—Ä–∞—É–∑–µ—Ä–Ω—ã–π –±–æ—Ç –∑–∞–∫—Ä—ã—Ç")
            except Exception as e:
                self.logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–∫—Ä—ã—Ç–∏—è –±—Ä–∞—É–∑–µ—Ä–Ω–æ–≥–æ –±–æ—Ç–∞: {e}")
    
    def print_download_statistics(self, new, updated, unchanged, failed):
        """–í—ã–≤–æ–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è"""
        total = new + updated + unchanged + failed
        
        if self.is_first_run:
            self.logger.info("üéØ –†–µ–∂–∏–º: –ü–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–æ–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
        else:
            self.logger.info("üîç –†–µ–∂–∏–º: –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏–∑–º–µ–Ω–µ–Ω–∏–π")
            
        self.logger.info("=" * 50)
        self.logger.info("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –°–ï–°–°–ò–ò:")
        self.logger.info(f"üÜï –ù–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤: {new}")
        self.logger.info(f"üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {updated}")
        self.logger.info(f"‚ö™ –ë–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π: {unchanged}")
        if failed > 0:
            self.logger.info(f"‚ùå –û—à–∏–±–æ–∫: {failed}")
        self.logger.info(f"üìÅ –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {total}")
        
    def generate_session_report(self):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫—Ä–∞—Ç–∫–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –æ —Å–µ—Å—Å–∏–∏"""
        try:
            from report_generator import ReportGenerator
            
            generator = ReportGenerator(self.config['download_dir'])
            
            # –ë—ã—Å—Ç—Ä–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            downloaded_files, discovered_files, first_run_data = generator.load_data()
            structure, total_size, total_files = generator.analyze_file_structure()
            
            self.logger.info("üìä –ö–†–ê–¢–ö–ò–ô –û–¢–ß–ï–¢:")
            self.logger.info(f"   üìÅ –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {total_files}")
            self.logger.info(f"   üíæ –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä: {generator.format_size(total_size)}")
            self.logger.info(f"   üîó –í –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö: {len(downloaded_files)} –∑–∞–ø–∏—Å–µ–π")
            
        except ImportError:
            self.logger.debug("–ú–æ–¥—É–ª—å –æ—Ç—á–µ—Ç–æ–≤ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–∞: {e}")
    
    def generate_full_report(self):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ–ª–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞"""
        try:
            from report_generator import ReportGenerator
            
            self.logger.info("üìã –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç...")
            generator = ReportGenerator(self.config['download_dir'])
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–æ–Ω—Å–æ–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
            generator.generate_console_report()
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º JSON –æ—Ç—á–µ—Ç
            json_file = generator.generate_json_report()
            self.logger.info(f"üíæ –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {json_file}")
            
        except ImportError:
            self.logger.warning("‚ö†Ô∏è –ú–æ–¥—É–ª—å –æ—Ç—á–µ—Ç–æ–≤ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ–ª–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞: {e}")

    def retry_failed_downloads(self):
        """–ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –Ω–µ—É–¥–∞—á–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
        self.logger.info("üîÑ –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–π–ª—ã –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è...")
        
        retry_count = 0
        for url, file_info in self.discovered_files['files'].items():
            if not file_info.get('downloaded', False):
                try:
                    self.logger.info(f"üîÑ –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞: {os.path.basename(url)}")
                    
                    save_dir = self.create_aifc_directory_structure(url, self.config['download_dir'])
                    filename = self.get_clean_filename(url)
                    save_path = os.path.join(save_dir, filename)
                    
                    result = self.download_with_browser_bot(url, save_path)
                    
                    if result in ["new", "updated"]:
                        retry_count += 1
                        self.logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —Å–∫–∞—á–∞–Ω –ø—Ä–∏ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–µ: {filename}")
                    
                except Exception as e:
                    self.logger.error(f"‚ùå –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ –Ω–µ—É–¥–∞—á–Ω–∞ –¥–ª—è {url}: {e}")
        
        if retry_count > 0:
            self.logger.info(f"üéâ –£—Å–ø–µ—à–Ω–æ —Å–∫–∞—á–∞–Ω–æ –ø—Ä–∏ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–∫–∞—Ö: {retry_count} —Ñ–∞–π–ª–æ–≤")
            self.save_downloaded_history()
            self.save_discovered_files()
        else:
            self.logger.info("üìÇ –ù–µ—Ç —Ñ–∞–π–ª–æ–≤ –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è")

    def test_classification_logic(self):
        """–¢–µ—Å—Ç–æ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
        test_urls = [
            "https://court.aifc.kz/files/legals/543/file/template-of-offering-materials-for-exempt-fund.pdf",
            "https://court.aifc.kz/files/legals/544/file/template-of-offering-materials-for-non-exempt-fund.pdf",
            "https://court.aifc.kz/uploads/judgments/case_no_1_2019.pdf",
            "https://court.aifc.kz/files/legals/577/file/guidance-on-spr-rus.pdf",
            "https://court.aifc.kz/files/legals/597/file/aifc-amlcft-practical-guidance_03-11-2023.pdf"
        ]
        
        print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:")
        for url in test_urls:
            path = self.create_aifc_directory_structure(url, "test_dir")
            print(f"URL: {url}")
            print(f"Path: {path}")
            print("-" * 50)

# –ê–ª–∏–∞—Å –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
DocumentMonitor = HumanLikeDocumentMonitor

def enable_long_paths_windows():
    """–í–∫–ª—é—á–µ–Ω–∏–µ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –¥–ª–∏–Ω–Ω—ã—Ö –ø—É—Ç–µ–π –≤ Windows (—Ç—Ä–µ–±—É–µ—Ç admin –ø—Ä–∞–≤)"""
    import subprocess
    import sys
    
    if os.name == 'nt':
        try:
            # –ü–æ–ø—ã—Ç–∫–∞ –≤–∫–ª—é—á–∏—Ç—å –¥–ª–∏–Ω–Ω—ã–µ –ø—É—Ç–∏ —á–µ—Ä–µ–∑ —Ä–µ–µ—Å—Ç—Ä
            cmd = [
                'reg', 'add', 
                'HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\FileSystem',
                '/v', 'LongPathsEnabled', '/t', 'REG_DWORD', '/d', '1', '/f'
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            if result.returncode == 0:
                print("‚úÖ –î–ª–∏–Ω–Ω—ã–µ –ø—É—Ç–∏ –≤–∫–ª—é—á–µ–Ω—ã –≤ —Ä–µ–µ—Å—Ç—Ä–µ Windows")
                print("‚ö†Ô∏è –¢—Ä–µ–±—É–µ—Ç—Å—è –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞ –¥–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π")
                return True
            else:
                print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –≤–∫–ª—é—á–∏—Ç—å –¥–ª–∏–Ω–Ω—ã–µ –ø—É—Ç–∏ (–Ω—É–∂–Ω—ã –ø—Ä–∞–≤–∞ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞)")
                return False
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ø—ã—Ç–∫–µ –≤–∫–ª—é—á–∏—Ç—å –¥–ª–∏–Ω–Ω—ã–µ –ø—É—Ç–∏: {e}")
            return False
    
    return True

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("ü§ñ –ß–µ–ª–æ–≤–µ–∫–æ–ø–æ–¥–æ–±–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ AIFC Court")
    print("=" * 50)
    
    # –ü–æ–ø—ã—Ç–∫–∞ –≤–∫–ª—é—á–∏—Ç—å –¥–ª–∏–Ω–Ω—ã–µ –ø—É—Ç–∏ –≤ Windows
    if os.name == 'nt':
        print("üîß –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–¥–µ—Ä–∂–∫—É –¥–ª–∏–Ω–Ω—ã—Ö –ø—É—Ç–µ–π –≤ Windows...")
        enable_long_paths_windows()
    
    monitor = HumanLikeDocumentMonitor()
    
    if not monitor.config['urls']:
        print("‚ö†Ô∏è –ù–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã URL –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞!")
        print(f"–û—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π—Ç–µ —Ñ–∞–π–ª '{monitor.config_file}' –∏ –¥–æ–±–∞–≤—å—Ç–µ URL –≤ —Å–µ–∫—Ü–∏—é 'urls'")
        return
    
    print(f"üéØ –ù–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ URL –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞:")
    for url in monitor.config['urls']:
        print(f"  ‚Ä¢ {url}")
    
    print(f"\nüìÅ –ü–∞–ø–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {monitor.config['download_dir']}")
    print(f"üé≠ –†–µ–∂–∏–º: –ò–º–∏—Ç–∞—Ü–∏—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å –±—Ä–∞—É–∑–µ—Ä–Ω—ã–º –±–æ—Ç–æ–º")
    print(f"üìè –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞: {monitor.config.get('max_filename_length', 150)} —Å–∏–º–≤–æ–ª–æ–≤")
    
    monitor.human_like_session()

if __name__ == "__main__":
    main()
