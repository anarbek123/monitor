"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è —Ä–µ–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ —É–∂–µ —Å–∫–∞—á–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –ø–æ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –ø–∞–ø–∫–∞–º
"""

import os
import json
import shutil
import logging
from pathlib import Path
from urllib.parse import urlparse

def setup_logging():
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('file_reorganizer.log', encoding='utf-8'),
            logging.StreamHandler()
        ]
    )
    return logging.getLogger(__name__)

def load_downloaded_files():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Å–∫–∞—á–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö"""
    try:
        with open('downloaded_files.json', 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        print("‚ùå –§–∞–π–ª downloaded_files.json –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        return {}

def classify_url(url):
    """–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è URL –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –ø–∞–ø–∫–∏"""
    url_lower = url.lower()
    
    # –°—É–¥–µ–±–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è –∏ –¥–µ–ª–∞
    if any(keyword in url_lower for keyword in [
        'judgments', '/uploads/', 'case%20no', 'judgment', 
        'case_no', 'case-no', 'decision', 'ruling'
    ]):
        return 'Judgments'
    
    # –ó–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–æ –∏ –ø—Ä–∞–≤–∏–ª–∞
    elif any(keyword in url_lower for keyword in [
        'legislation', '/legals/', 'regulations', 'rules', 
        'policy', 'consultation-paper', 'guidance', 'notice',
        'amendment', 'circular', 'directive', 'order'
    ]):
        return 'Legislation'
    
    # –°–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ AIFC
    elif any(keyword in url_lower for keyword in [
        'aifc-court-regulations', 'aifc-court-rules', 
        'template-of-offering', 'afsa-policy'
    ]):
        return 'Legislation'
    
    else:
        return 'Other_Documents'

def get_correct_path(url, base_dir):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –ø—É—Ç–∏ –¥–ª—è —Ñ–∞–π–ª–∞"""
    folder_name = classify_url(url)
    
    # –°–æ–∑–¥–∞–µ–º –æ—Å–Ω–æ–≤–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
    correct_path = os.path.join(base_dir, 'AIFC_Court', folder_name)
    
    # –î–ª—è —Ä–µ—à–µ–Ω–∏–π —Å—É–¥–æ–≤ —Å–æ–∑–¥–∞–µ–º –ø–æ–¥–ø–∞–ø–∫–∏ –ø–æ –≥–æ–¥–∞–º
    if folder_name == 'Judgments':
        import re
        year_match = re.search(r'20\d{2}', url)
        if year_match:
            year = year_match.group()
            correct_path = os.path.join(correct_path, year)
    
    # –î–ª—è –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–∞ —Å–æ–∑–¥–∞–µ–º –ø–æ–¥–ø–∞–ø–∫–∏ –ø–æ —Ç–∏–ø—É
    elif folder_name == 'Legislation':
        url_lower = url.lower()
        if 'consultation-paper' in url_lower:
            correct_path = os.path.join(correct_path, 'Consultation_Papers')
        elif 'guidance' in url_lower:
            correct_path = os.path.join(correct_path, 'Guidance_Documents')
        elif 'notice' in url_lower:
            correct_path = os.path.join(correct_path, 'Notices')
        elif 'template' in url_lower:
            correct_path = os.path.join(correct_path, 'Templates')
    
    return correct_path

def reorganize_files():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ä–µ–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ —Ñ–∞–π–ª–æ–≤"""
    logger = setup_logging()
    
    logger.info("üöÄ –ù–∞—á–∏–Ω–∞–µ–º —Ä–µ–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—é —Ñ–∞–π–ª–æ–≤...")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–∫–∞—á–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö
    downloaded_files = load_downloaded_files()
    
    if not downloaded_files:
        logger.error("‚ùå –ù–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Å–∫–∞—á–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö")
        return
    
    base_dir = "aifc_documents"
    moved_count = 0
    error_count = 0
    already_correct_count = 0
    
    logger.info(f"üìä –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏: {len(downloaded_files)}")
    
    for url, file_info in downloaded_files.items():
        try:
            current_path = file_info.get('path', '')
            
            if not current_path or not os.path.exists(current_path):
                logger.warning(f"‚ö†Ô∏è –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {current_path}")
                error_count += 1
                continue
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø—É—Ç—å
            correct_dir = get_correct_path(url, base_dir)
            filename = os.path.basename(current_path)
            correct_path = os.path.join(correct_dir, filename)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –ø–µ—Ä–µ–º–µ—â–∞—Ç—å
            if os.path.normpath(current_path) == os.path.normpath(correct_path):
                logger.debug(f"‚úÖ –§–∞–π–ª —É–∂–µ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –ø–∞–ø–∫–µ: {filename}")
                already_correct_count += 1
                continue
            
            # –°–æ–∑–¥–∞–µ–º —Ü–µ–ª–µ–≤—É—é –ø–∞–ø–∫—É
            os.makedirs(correct_dir, exist_ok=True)
            
            # –ï—Å–ª–∏ —Ü–µ–ª–µ–≤–æ–π —Ñ–∞–π–ª —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, —Å–æ–∑–¥–∞–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é
            if os.path.exists(correct_path):
                backup_path = correct_path + ".backup"
                counter = 1
                while os.path.exists(backup_path):
                    backup_path = f"{correct_path}.backup{counter}"
                    counter += 1
                
                shutil.move(correct_path, backup_path)
                logger.info(f"üîÑ –°–æ–∑–¥–∞–Ω–∞ —Ä–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è: {os.path.basename(backup_path)}")
            
            # –ü–µ—Ä–µ–º–µ—â–∞–µ–º —Ñ–∞–π–ª
            shutil.move(current_path, correct_path)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –ø—É—Ç—å –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
            downloaded_files[url]['path'] = correct_path
            downloaded_files[url]['moved_at'] = str(Path().cwd())
            
            logger.info(f"üìÅ –ü–µ—Ä–µ–º–µ—â–µ–Ω: {filename}")
            logger.info(f"   –ò–∑: {current_path}")
            logger.info(f"   –í:  {correct_path}")
            
            moved_count += 1
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 10 —Ñ–∞–π–ª–æ–≤
            if moved_count % 10 == 0:
                save_updated_database(downloaded_files)
                logger.info(f"üíæ –ü—Ä–æ–≥—Ä–µ—Å—Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {moved_count} —Ñ–∞–π–ª–æ–≤ –ø–µ—Ä–µ–º–µ—â–µ–Ω–æ")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {url}: {e}")
            error_count += 1
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—É—é –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
    save_updated_database(downloaded_files)
    
    # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    logger.info("=" * 50)
    logger.info("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –†–ï–û–†–ì–ê–ù–ò–ó–ê–¶–ò–ò:")
    logger.info(f"üìÅ –§–∞–π–ª–æ–≤ –ø–µ—Ä–µ–º–µ—â–µ–Ω–æ: {moved_count}")
    logger.info(f"‚úÖ –£–∂–µ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –ø–∞–ø–∫–∞—Ö: {already_correct_count}")
    logger.info(f"‚ùå –û—à–∏–±–æ–∫: {error_count}")
    logger.info(f"üìã –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(downloaded_files)}")
    
    # –û—á–∏—â–∞–µ–º –ø—É—Å—Ç—ã–µ –ø–∞–ø–∫–∏
    cleanup_empty_directories(base_dir)
    
    logger.info("üéâ –†–µ–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")

def save_updated_database(downloaded_files):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω–æ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    with open('downloaded_files.json', 'w', encoding='utf-8') as f:
        json.dump(downloaded_files, f, indent=2, ensure_ascii=False)

def cleanup_empty_directories(base_dir):
    """–£–¥–∞–ª–µ–Ω–∏–µ –ø—É—Å—Ç—ã—Ö –ø–∞–ø–æ–∫"""
    logger = logging.getLogger(__name__)
    
    try:
        for root, dirs, files in os.walk(base_dir, topdown=False):
            for dir_name in dirs:
                dir_path = os.path.join(root, dir_name)
                try:
                    # –ü—ã—Ç–∞–µ–º—Å—è —É–¥–∞–ª–∏—Ç—å –ø–∞–ø–∫—É (—É–¥–∞–ª–∏—Ç—Å—è —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –ø—É—Å—Ç–∞—è)
                    os.rmdir(dir_path)
                    logger.info(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–∞ –ø—É—Å—Ç–∞—è –ø–∞–ø–∫–∞: {dir_path}")
                except OSError:
                    # –ü–∞–ø–∫–∞ –Ω–µ –ø—É—Å—Ç–∞—è - —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ
                    pass
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ –ø—É—Å—Ç—ã—Ö –ø–∞–ø–æ–∫: {e}")

def preview_reorganization():
    """–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä –∏–∑–º–µ–Ω–µ–Ω–∏–π –±–µ–∑ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏—è"""
    logger = setup_logging()
    
    logger.info("üëÄ –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä —Ä–µ–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏...")
    
    downloaded_files = load_downloaded_files()
    
    if not downloaded_files:
        return
    
    base_dir = "aifc_documents"
    changes = []
    
    for url, file_info in downloaded_files.items():
        current_path = file_info.get('path', '')
        
        if not current_path:
            continue
        
        correct_dir = get_correct_path(url, base_dir)
        filename = os.path.basename(current_path)
        correct_path = os.path.join(correct_dir, filename)
        
        if os.path.normpath(current_path) != os.path.normpath(correct_path):
            changes.append({
                'filename': filename,
                'current': current_path,
                'correct': correct_path,
                'url': url
            })
    
    if changes:
        logger.info(f"üìã –ü–ª–∞–Ω–∏—Ä—É–µ—Ç—Å—è –ø–µ—Ä–µ–º–µ—Å—Ç–∏—Ç—å {len(changes)} —Ñ–∞–π–ª–æ–≤:")
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ç–∏–ø–∞–º
        by_type = {}
        for change in changes:
            folder_type = classify_url(change['url'])
            if folder_type not in by_type:
                by_type[folder_type] = []
            by_type[folder_type].append(change)
        
        for folder_type, files in by_type.items():
            logger.info(f"\nüìÇ {folder_type}: {len(files)} —Ñ–∞–π–ª–æ–≤")
            for file_info in files[:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5
                logger.info(f"   ‚Ä¢ {file_info['filename']}")
            if len(files) > 5:
                logger.info(f"   ... –∏ –µ—â–µ {len(files) - 5} —Ñ–∞–π–ª–æ–≤")
    else:
        logger.info("‚úÖ –í—Å–µ —Ñ–∞–π–ª—ã —É–∂–µ –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤ –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –ø–∞–ø–∫–∞—Ö!")

if __name__ == "__main__":
    print("üîß –£—Ç–∏–ª–∏—Ç–∞ —Ä–µ–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ —Ñ–∞–π–ª–æ–≤ AIFC Court")
    print("=" * 50)
    
    choice = input("–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:\n1. –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä\n2. –í—ã–ø–æ–ª–Ω–∏—Ç—å —Ä–µ–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—é\n–í–∞—à –≤—ã–±–æ—Ä (1/2): ")
    
    if choice == "1":
        preview_reorganization()
    elif choice == "2":
        confirm = input("‚ö†Ô∏è –≠—Ç–æ –ø–µ—Ä–µ–º–µ—Å—Ç–∏—Ç —Ñ–∞–π–ª—ã! –ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å? (–¥–∞/–Ω–µ—Ç): ")
        if confirm.lower() in ['–¥–∞', 'yes', 'y']:
            reorganize_files()
        else:
            print("‚ùå –û–ø–µ—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞")
    else:
        print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä")