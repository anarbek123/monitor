"""
–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –æ—Ç—á–µ—Ç–æ–≤ –¥–ª—è AIFC Court Document Monitor
"""

import os
import json
import logging
from datetime import datetime, timedelta
from collections import defaultdict, Counter
import re

class ReportGenerator:
    def __init__(self, download_dir="aifc_documents"):
        self.download_dir = download_dir
        self.logger = logging.getLogger(__name__)
        
    def load_data(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ñ–∞–π–ª–æ–≤ —Å–∏—Å—Ç–µ–º—ã"""
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é —Å–∫–∞—á–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
            with open('downloaded_files.json', 'r', encoding='utf-8') as f:
                downloaded_files = json.load(f)
        except FileNotFoundError:
            downloaded_files = {}
            
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
            with open('discovered_files.json', 'r', encoding='utf-8') as f:
                discovered_files = json.load(f)
        except FileNotFoundError:
            discovered_files = {'files': {}}
            
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å –ø–µ—Ä–≤–æ–≥–æ –∑–∞–ø—É—Å–∫–∞
            with open('first_run_completed.json', 'r', encoding='utf-8') as f:
                first_run_data = json.load(f)
        except FileNotFoundError:
            first_run_data = {'completed': False}
            
        return downloaded_files, discovered_files, first_run_data
    
    def analyze_file_structure(self):
        """–ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ñ–∞–π–ª–æ–≤ –Ω–∞ –¥–∏—Å–∫–µ"""
        structure = {}
        total_size = 0
        file_count = 0
        
        if not os.path.exists(self.download_dir):
            return structure, total_size, file_count
            
        for root, dirs, files in os.walk(self.download_dir):
            for file in files:
                file_path = os.path.join(root, file)
                try:
                    file_size = os.path.getsize(file_path)
                    total_size += file_size
                    file_count += 1
                    
                    # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å –æ—Ç –±–∞–∑–æ–≤–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
                    rel_path = os.path.relpath(root, self.download_dir)
                    
                    if rel_path not in structure:
                        structure[rel_path] = {
                            'files': [],
                            'total_size': 0,
                            'count': 0
                        }
                    
                    structure[rel_path]['files'].append({
                        'name': file,
                        'size': file_size,
                        'modified': datetime.fromtimestamp(os.path.getmtime(file_path))
                    })
                    structure[rel_path]['total_size'] += file_size
                    structure[rel_path]['count'] += 1
                    
                except OSError:
                    continue
                    
        return structure, total_size, file_count
    
    def categorize_documents(self, downloaded_files):
        """–ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø–æ —Ç–∏–ø–∞–º"""
        categories = {
            'judgments': {
                'by_year': defaultdict(list),
                'total': 0,
                'size': 0
            },
            'legislation': {
                'by_type': defaultdict(list),
                'total': 0,
                'size': 0
            },
            'other': {
                'files': [],
                'total': 0,
                'size': 0
            }
        }
        
        for url, info in downloaded_files.items():
            file_size = info.get('size', 0)
            
            if 'judgment' in url.lower() or '/uploads/' in url.lower():
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –≥–æ–¥ –∏–∑ URL
                year_match = re.search(r'20\d{2}', url)
                year = year_match.group() if year_match else 'Unknown'
                
                categories['judgments']['by_year'][year].append({
                    'url': url,
                    'path': info.get('path', ''),
                    'size': file_size,
                    'downloaded_at': info.get('downloaded_at', '')
                })
                categories['judgments']['total'] += 1
                categories['judgments']['size'] += file_size
                
            elif 'legislation' in url.lower():
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–∞
                leg_type = 'General'
                if 'companies' in url.lower():
                    leg_type = 'Companies'
                elif 'partnership' in url.lower():
                    leg_type = 'Partnership'
                elif 'financial' in url.lower():
                    leg_type = 'Financial Services'
                elif 'aml' in url.lower() or 'anti-money' in url.lower():
                    leg_type = 'AML/CFT'
                elif 'fees' in url.lower():
                    leg_type = 'Fees'
                elif 'conduct' in url.lower():
                    leg_type = 'Conduct of Business'
                
                categories['legislation']['by_type'][leg_type].append({
                    'url': url,
                    'path': info.get('path', ''),
                    'size': file_size,
                    'downloaded_at': info.get('downloaded_at', '')
                })
                categories['legislation']['total'] += 1
                categories['legislation']['size'] += file_size
                
            else:
                categories['other']['files'].append({
                    'url': url,
                    'path': info.get('path', ''),
                    'size': file_size,
                    'downloaded_at': info.get('downloaded_at', '')
                })
                categories['other']['total'] += 1
                categories['other']['size'] += file_size
                
        return categories
    
    def format_size(self, size_bytes):
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–∞"""
        if size_bytes == 0:
            return "0 B"
        
        size_names = ["B", "KB", "MB", "GB"]
        import math
        i = int(math.floor(math.log(size_bytes, 1024)))
        p = math.pow(1024, i)
        s = round(size_bytes / p, 2)
        return f"{s} {size_names[i]}"
    
    def analyze_activity(self, downloaded_files):
        """–ê–Ω–∞–ª–∏–∑ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è"""
        activity = {
            'by_date': defaultdict(int),
            'by_hour': defaultdict(int),
            'by_method': defaultdict(int),
            'recent_activity': []
        }
        
        now = datetime.now()
        recent_threshold = now - timedelta(days=7)
        
        for url, info in downloaded_files.items():
            try:
                download_time = datetime.fromisoformat(info.get('downloaded_at', ''))
                
                # –ü–æ –¥–Ω—è–º
                date_str = download_time.strftime('%Y-%m-%d')
                activity['by_date'][date_str] += 1
                
                # –ü–æ —á–∞—Å–∞–º
                hour = download_time.hour
                activity['by_hour'][hour] += 1
                
                # –ü–æ –º–µ—Ç–æ–¥–∞–º
                method = info.get('method', 'unknown')
                activity['by_method'][method] += 1
                
                # –ù–µ–¥–∞–≤–Ω—è—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
                if download_time >= recent_threshold:
                    activity['recent_activity'].append({
                        'url': url,
                        'path': info.get('path', ''),
                        'size': info.get('size', 0),
                        'time': download_time,
                        'method': method
                    })
                    
            except (ValueError, TypeError):
                continue
                
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–µ–¥–∞–≤–Ω—é—é –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        activity['recent_activity'].sort(key=lambda x: x['time'], reverse=True)
        
        return activity
    
    def generate_console_report(self):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –¥–ª—è –∫–æ–Ω—Å–æ–ª–∏"""
        print("\n" + "=" * 80)
        print("üìä –û–¢–ß–ï–¢ AIFC COURT DOCUMENT MONITOR")
        print("=" * 80)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        downloaded_files, discovered_files, first_run_data = self.load_data()
        structure, total_disk_size, total_disk_files = self.analyze_file_structure()
        categories = self.categorize_documents(downloaded_files)
        activity = self.analyze_activity(downloaded_files)
        
        # –û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        print(f"\nüìà –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        print(f"   üìÅ –ü–∞–ø–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {self.download_dir}")
        print(f"   üìÑ –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤ –Ω–∞ –¥–∏—Å–∫–µ: {total_disk_files}")
        print(f"   üíæ –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä: {self.format_size(total_disk_size)}")
        print(f"   üîó –§–∞–π–ª–æ–≤ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö: {len(downloaded_files)}")
        print(f"   üïê –ü–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫ –∑–∞–≤–µ—Ä—à–µ–Ω: {'‚úÖ –î–∞' if first_run_data.get('completed') else '‚ùå –ù–µ—Ç'}")
        
        if first_run_data.get('completed'):
            completed_at = first_run_data.get('completed_at')
            if completed_at:
                try:
                    completed_time = datetime.fromisoformat(completed_at)
                    print(f"   üìÖ –î–∞—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è: {completed_time.strftime('%d.%m.%Y %H:%M')}")
                except:
                    pass
        
        # –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–∞–ø–æ–∫
        print(f"\nüìÇ –°–¢–†–£–ö–¢–£–†–ê –ü–ê–ü–û–ö:")
        for folder, info in sorted(structure.items()):
            if folder == '.':
                folder_name = f"{self.download_dir} (–∫–æ—Ä–µ–Ω—å)"
            else:
                folder_name = folder.replace('\\', ' ‚Üí ')
            
            print(f"   üìÅ {folder_name}")
            print(f"      üìÑ –§–∞–π–ª–æ–≤: {info['count']}")
            print(f"      üíæ –†–∞–∑–º–µ—Ä: {self.format_size(info['total_size'])}")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Ñ–∞–π–ª–æ–≤
            recent_files = sorted(info['files'], key=lambda x: x['modified'], reverse=True)[:3]
            for file_info in recent_files:
                print(f"         ‚Ä¢ {file_info['name']} ({self.format_size(file_info['size'])})")
            
            if len(info['files']) > 3:
                print(f"         ... –∏ –µ—â–µ {len(info['files']) - 3} —Ñ–∞–π–ª–æ–≤")
        
        # –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        print(f"\nüìã –ö–ê–¢–ï–ì–û–†–ò–ò –î–û–ö–£–ú–ï–ù–¢–û–í:")
        
        # –†–µ—à–µ–Ω–∏—è —Å—É–¥–∞
        judgments = categories['judgments']
        print(f"   ‚öñÔ∏è –†–ï–®–ï–ù–ò–Ø –°–£–î–ê: {judgments['total']} —Ñ–∞–π–ª–æ–≤ ({self.format_size(judgments['size'])})")
        for year, files in sorted(judgments['by_year'].items()):
            year_size = sum(f['size'] for f in files)
            print(f"      üìÖ {year}: {len(files)} —Ä–µ—à–µ–Ω–∏–π ({self.format_size(year_size)})")
        
        # –ó–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–æ
        legislation = categories['legislation']
        print(f"   üìú –ó–ê–ö–û–ù–û–î–ê–¢–ï–õ–¨–°–¢–í–û: {legislation['total']} —Ñ–∞–π–ª–æ–≤ ({self.format_size(legislation['size'])})")
        for leg_type, files in sorted(legislation['by_type'].items()):
            type_size = sum(f['size'] for f in files)
            print(f"      üìë {leg_type}: {len(files)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ ({self.format_size(type_size)})")
        
        # –ü—Ä–æ—á–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
        other = categories['other']
        if other['total'] > 0:
            print(f"   üìé –ü–†–û–ß–ò–ï: {other['total']} —Ñ–∞–π–ª–æ–≤ ({self.format_size(other['size'])})")
        
        # –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
        print(f"\nüìà –ê–ö–¢–ò–í–ù–û–°–¢–¨ –°–ö–ê–ß–ò–í–ê–ù–ò–Ø:")
        
        # –ü–æ –º–µ—Ç–æ–¥–∞–º
        print(f"   üîß –ü–æ –º–µ—Ç–æ–¥–∞–º:")
        for method, count in activity['by_method'].items():
            method_name = {
                'browser_bot': 'ü§ñ –ë—Ä–∞—É–∑–µ—Ä–Ω—ã–π –±–æ—Ç',
                'requests': 'üì° HTTP –∑–∞–ø—Ä–æ—Å—ã',
                'unknown': '‚ùì –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'
            }.get(method, method)
            print(f"      {method_name}: {count} —Ñ–∞–π–ª–æ–≤")
        
        # –ù–µ–¥–∞–≤–Ω—è—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
        recent = activity['recent_activity'][:10]  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 10
        if recent:
            print(f"\n   üïê –ù–ï–î–ê–í–ù–Ø–Ø –ê–ö–¢–ò–í–ù–û–°–¢–¨ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π):")
            for item in recent:
                time_str = item['time'].strftime('%d.%m %H:%M')
                filename = os.path.basename(item['path']) if item['path'] else 'unknown'
                size_str = self.format_size(item['size'])
                method_icon = 'ü§ñ' if item['method'] == 'browser_bot' else 'üì°'
                print(f"      {method_icon} {time_str} - {filename} ({size_str})")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —á–∞—Å–∞–º (—Ç–æ–ø-5)
        hourly_stats = sorted(activity['by_hour'].items(), key=lambda x: x[1], reverse=True)[:5]
        if hourly_stats:
            print(f"\n   ‚è∞ –°–ê–ú–´–ï –ê–ö–¢–ò–í–ù–´–ï –ß–ê–°–´:")
            for hour, count in hourly_stats:
                print(f"      {hour:02d}:00 - {count} —Ñ–∞–π–ª–æ–≤")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        print(f"\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
        
        total_files = len(downloaded_files)
        if total_files == 0:
            print("   ‚Ä¢ –ó–∞–ø—É—Å—Ç–∏—Ç–µ –ø–µ—Ä–≤–æ–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
        elif not first_run_data.get('completed'):
            print("   ‚Ä¢ –ó–∞–≤–µ—Ä—à–∏—Ç–µ –ø–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–æ–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ")
        else:
            print("   ‚Ä¢ –°–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ —Ä–µ–∂–∏–º–µ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–≤–µ–∂–µ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
            try:
                last_scan = discovered_files.get('last_full_scan')
                if last_scan:
                    last_time = datetime.fromisoformat(last_scan)
                    days_ago = (datetime.now() - last_time).days
                    if days_ago > 3:
                        print(f"   ‚Ä¢ –ü–æ—Å–ª–µ–¥–Ω–µ–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –±—ã–ª–æ {days_ago} –¥–Ω–µ–π –Ω–∞–∑–∞–¥ - —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø—Ä–æ–≤–µ—Ä–∫–∞")
            except:
                pass
                
            if len(recent) == 0:
                print("   ‚Ä¢ –ù–µ—Ç –Ω–µ–¥–∞–≤–Ω–µ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ - –ø—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞")
        
        print("=" * 80)
    
    def generate_json_report(self, output_file="aifc_report.json"):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è JSON –æ—Ç—á–µ—Ç–∞"""
        downloaded_files, discovered_files, first_run_data = self.load_data()
        structure, total_disk_size, total_disk_files = self.analyze_file_structure()
        categories = self.categorize_documents(downloaded_files)
        activity = self.analyze_activity(downloaded_files)
        
        report = {
            'generated_at': datetime.now().isoformat(),
            'summary': {
                'download_directory': self.download_dir,
                'total_files_on_disk': total_disk_files,
                'total_disk_size': total_disk_size,
                'total_disk_size_formatted': self.format_size(total_disk_size),
                'files_in_database': len(downloaded_files),
                'first_run_completed': first_run_data.get('completed', False),
                'first_run_completed_at': first_run_data.get('completed_at')
            },
            'folder_structure': structure,
            'document_categories': categories,
            'activity_analysis': activity,
            'discovered_files_count': len(discovered_files.get('files', {})),
            'last_scan': discovered_files.get('last_full_scan')
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False, default=str)
        
        return output_file

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –æ—Ç—á–µ—Ç–∞"""
    generator = ReportGenerator()
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–æ–Ω—Å–æ–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
    generator.generate_console_report()
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º JSON –æ—Ç—á–µ—Ç
    json_file = generator.generate_json_report()
    print(f"\nüíæ JSON –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {json_file}")

if __name__ == "__main__":
    import logging
    logging.basicConfig(level=logging.INFO)
    main()